# -*- coding: utf-8 -*-
"""Lista 3 - Pré Processamento (Davi).ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1uBN_fx5GGZH6PV4YhgOB8XzeII1euyzY

## 1. Importe as bibliotecas pandas, numpy, seaborn, matplotlib.pyplot e quaisquer outras que você necessitar.
"""

import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
from sklearn.preprocessing import StandardScaler

"""##2. Carregue o dataset em um dataframe."""

df = pd.read_csv('/content/data.csv')
df

"""##3. Quais são as 5 primeiras linhas do dataset?"""

df.head()

"""##4. Quais são as 5 últimas linhas do dataset?"""

df.tail()

"""##5. Qual é o formato do dataset (quantidade de linhas e colunas)?"""

Linhas = df.shape[0] 
Colunas = df.shape[1] 
print("Linhas: " + str(Linhas)) 
print("Colunas: " + str(Colunas))

"""##6. Quais são os tipos de dados do dataset?"""

df.dtypes

"""##7. Renomei as colunas para a seguir conforme descrito abaixo:
###Engine HP = HP, Engine Cylinders = Cylinders, Transmission Type= Transmission, Driven_Wheels = Drive Mode, highway MPG = MPG-H, city mpg = MPG-C, MSRP = Price
"""

df = df.rename(columns={'Engine HP': 'HP', 'Engine Cylinders': 'Cylinders', 'Transmission Type': 'Transmission', 'Driven_Wheels': 'Drive Mode', 'highway MPG': 'MPG-H', 'city mpg': 'MPG-C', 'MSRP': 'Price'}) 
df

"""##8. O dataset possuí colunas com valores nulos? Se sim, quais são? Qual a quantidade e Qual a porcentagem que esses registros representam dos valores da coluna?"""

# Utlizando o método isnull() para identificar os valores nulos e sum() para somá-los
valores_nulos = df.isnull().sum()
# Contando o número total de registros do dataset para realizar o cálculo de porcentagem
quantidade_registros = df.count()
# Calculo da porcentagem de valores nulos
porcentagem_valores_nulos = (valores_nulos / quantidade_registros) * 100
# Exibe quais são os valores nulos para cada coluna
for coluna in df.columns:
  # Exibirá essa informação apenas das colunas que possuírem valores nulos
    if valores_nulos[coluna] > 0:
        print('Na coluna', coluna, 'possuem', valores_nulos[coluna], 'valores nulos (', '{0:.2f}%'.format(porcentagem_valores_nulos[coluna]), 'do total ).')

"""##9. Depois de remover as linhas com valores nulos e sobreescreva o dataframe, qual a quantidade de linhas restou?"""

df.dropna(inplace=True)
df_sem_valores_nulos = df.dropna()
df_sem_valores_nulos

linhas_sem_valores_nulos = df.shape[0]  
print("Linhas não nulas restantes no DataFrame: " + str(linhas_sem_valores_nulos))

"""##10. O dataset possuí linhas duplicadas? Se sim, quantas?"""

df = pd.read_csv('/content/data.csv')
df
# Identificando as linhas duplicadas
valores_duplicados = df.duplicated()

# Calculando o total de linhas duplicadas
total_valores_duplicados = valores_duplicados.sum()
print('O dataset possui', total_valores_duplicados, 'linhas duplicadas.')

"""##11. Depois de remover as linhas duplicadas e sobreescreva o dataframe, qual a quantidade de linhas restou?"""

# Removendo as linhas duplicadas
df_sem_valores_duplicados = df.drop_duplicates()

# Sobrecrevendo o dataframe original
df.drop_duplicates(inplace=True)
df_sem_valores_duplicados

linhas_sem_valores_duplicados = df_sem_valores_duplicados.shape[0]  
print("Linhas não duplicadas restantes no DataFrame: " + str(linhas_sem_valores_duplicados))

"""##12. Qual é a quantidade e a proporção (porcentagem) do tamanho dos carros no dataset?"""

# Contar a quantidade do tamanho dos carros na coluna
quantidade = df["Vehicle Size"].value_counts()
# Calcular a porcentagem de cada tamanho dos carros na coluna
porcentagem = df["Vehicle Size"].value_counts(normalize=True)
print(quantidade)
print(porcentagem*100)

"""##13. Quantas marcas de carros distintas o dataset possui?"""

print(df["Make"].value_counts())
# Contar quantos registros de dados diferentes em uma coluna específica
print('Existem', df["Make"].nunique(), 'registros de marcas de carros distintas.')

"""##14. Faça os seguintes gráficos:

###a) Boxplot da coluna ‘HP’;
"""

# Criando o boxplot
sns.boxplot(df['Engine HP'])

# Adicionando título e nome dos eixos
plt.title('Boxplot da coluna HP')
plt.ylabel('HP')

# Plotando o gráfico
plt.show()

"""###b) Distribuição da coluna ‘HP’;"""

# Plotando o histograma e a curva de densidade
sns.histplot(data=df, x='Engine HP', kde=True)

# Adicionando título e nome dos eixos
plt.title('Distribuição da Coluna HP')
plt.xlabel('HP')
plt.ylabel('Ocorrência')

# Plotando o gráfico
plt.show()

"""###c) Gráfico de dispersão entre as colunas HP e Prince, com cores diferentes para cada tipo de ‘Vehicle Size’ (tudo no mesmo gráfico);"""

# Plotando o gráfico de dispersão com cores diferentes para cada tipo de 'Vehicle Size'
sns.scatterplot(data=df, x='Engine HP', y='MSRP', hue='Vehicle Size')

# Adicionando título e nome dos eixos
plt.title('Gráfico de Dispersão')
plt.xlabel('HP')
plt.ylabel('Price')

# Plotando o gráfico
plt.show()

"""###d) Boxplot da coluna ‘Year’;"""

# Criando o boxplot
plt.boxplot(df['Year'])

# Adicionando título e nome dos eixos
plt.title('Boxplot da coluna Year')
plt.ylabel('Year')

# Plotando o gráfico
plt.show()

"""###e) Distribuição da coluna ‘Year’;"""

# Plotando o histograma e a curva de densidade
sns.histplot(data=df, x='Year', kde=True)

# Adicionando título e nome dos eixos
plt.title('Distribuição da Coluna Year')
plt.xlabel('Year')
plt.ylabel('Ocorrência')

# Plotando o gráfico
plt.show()

"""##15. Qual é a marca de carro que possuí mais carros no dataset?"""

# Descobrir qual valor se repete com mais frequência em uma coluna específica
print('A marca de carro que possuí mais carros no dataset é a', df["Make"].mode().iloc[0])

"""##16. Qual é o somatório dos valores de todos os veículos da marca que possuí o maior números de carros do dataset?"""

# Contar os valores apenas do dado que mais se repete na coluna Make
print('Existem', df["Make"].value_counts().max(), 'veículos da marca Chevrolet no dataset.')

"""##17. Calcule a correlação entre as colunas e crie um gráfico.

"""

# Calculando a correlação entre as colunas
correlacao = df.corr()

# Criando um gráfico de calor indicando a correlação
plt.imshow(correlacao, cmap='coolwarm')
plt.colorbar()
plt.xticks(range(len(df.columns)), df.columns, rotation=90)
plt.yticks(range(len(df.columns)), df.columns)
plt.show()

"""##18. O dataset possuí variáveis com correlação superior a 70% (podendo ser negativa ou positiva)? Se possuir, quais são elas e qual a correlação?"""

# Filtrando as correlações maiores que 0.7 ou menores que -0.7
new_correlacao = correlacao[(correlacao > 0.7) | (correlacao < -0.7)]

# Mostrando apenas as correlações maiores que 0.7 ou menores que -0.7 e removendo valores duplicados
print(new_correlacao.unstack()[new_correlacao.unstack() != 1].dropna().drop_duplicates())

"""##19. Qual é o 90º percentile dos preços dos veículos?"""

percentile90 = df['MSRP'].quantile(q=0.9)
percentile90

"""##20. De quais marcas são os veículos de maior e menor valor do tipo Compact?"""

# Filtrando a coluna 'Vehicle Size' apenas por registros do tipo Compact
df_filtrado = df.loc[df['Vehicle Size'] == 'Compact']
# Filtrando o valor mínimo e máximo da coluna 'MSRP' do novo df_filtrado
idx_min = df_filtrado['MSRP'].idxmin()
idx_max = df_filtrado['MSRP'].idxmax()
df_filtrado_novo = df_filtrado.loc[[idx_min, idx_max]]
# Filtrando apenas as colunas que serão relevantes para se comparar os parâmetros requisitados
df_filtrado_novo = df_filtrado_novo.drop(['Model', 'Year', 'Engine Fuel Type', 'Engine HP', 'Engine Cylinders', 'Transmission Type', 'Driven_Wheels', 'Number of Doors', 'Market Category', 'Vehicle Style', 'highway MPG', 'city mpg', 'Popularity'], axis=1)
df_filtrado_novo

"""##21. Como ficaria o dataset se os dados numéricos fossem normalizados?"""

df = pd.read_csv('/content/data.csv')
df
# Usando a biblioteca scikit-learn para criar um objeto StandardScaler 
scaler = StandardScaler()

# Normalização do tipo Z-score, que transforma os dados para ter média zero e desvio padrão unitário. Ou seja, as colunas do tipo object não serão normalizadas.
df[df.select_dtypes(include=['int', 'float']).columns] = scaler.fit_transform(df.select_dtypes(include=['int', 'float']))
df

"""##22. Faça o One-hot enconding (binário) das colunas categóricas do dataset."""

df = pd.read_csv('/content/data.csv')
df
# Realizando o one-hot encoding (converter variáveis categóricas em um formato numérico)
df = pd.get_dummies(df, columns=['Make', 'Model', 'Engine Fuel Type', 'Transmission Type', 'Driven_Wheels', 'Market Category', 'Vehicle Size', 'Vehicle Style'])
df

"""##23. Quais são as 10 primeiras linhas do dataset?"""

df = pd.read_csv('/content/data.csv')
df.head(10)

"""##Considere um modelo de classificação binária que foi treinado e testado com as seguintes previsões:

###y_true = [1, 0, 1, 0, 1, 0, 1, 1, 0, 0]
###y_pred = [1, 0, 1, 1, 0, 0, 1, 1, 1, 0]

##Utilizando o Scikit-learn, calcule a acurácia, precisão, recall e F1 do modelo.

"""

from sklearn import metrics

y_true = [1, 0, 1, 0, 1, 0, 1, 1, 0, 0]
y_pred = [1, 0, 1, 1, 0, 0, 1, 1, 1, 0]

# Cálculo da acurácia
acuracia = metrics.accuracy_score(y_true, y_pred)
print("Acurácia:", acuracia)

# Cálculo da precisão
precisao = metrics.precision_score(y_true, y_pred)
print("Precisão:", precisao)

# Cálculo do recall
recall = metrics.recall_score(y_true, y_pred)
print("Recall:", recall)

# Cálculo do F1-score
f1_score = metrics.f1_score(y_true, y_pred)
print("F1-score:", f1_score)

"""##Considere um modelo de regressão linear com os seguintes dados observados:
###y_true = [10, 20, 30, 40, 50, 60, 70, 80, 90, 100]
###y_pred = [12, 25, 35, 42, 49, 62, 75, 82, 93, 105]
##Utilizando Sklearn, calcule as métricas MSE, RMSE, MAE e R² para avaliar o desempenho do modelo.

"""

from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score
import numpy as np

y_true = np.array([10, 20, 30, 40, 50, 60, 70, 80, 90, 100])
y_pred = np.array([12, 25, 35, 42, 49, 62, 75, 82, 93, 105])

# MSE - Erro Quadrático Médio
mse = mean_squared_error(y_true, y_pred)
print("MSE:", mse)

# RMSE - Raiz do erro quadrático médio
rmse = np.sqrt(mse)
print("RMSE:", rmse)

# MAE - Erro Absoluto Médio
mae = mean_absolute_error(y_true, y_pred)
print("MAE:", mae)

# R² - R Quadrado
r2 = r2_score(y_true, y_pred)
print("R²:", r2)